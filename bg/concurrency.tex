\section{Concurrent Programming} % (fold)
\label{sec:concurrent}
Concurrent programming has become an increasingly important issue over the
last decade due to the introduction of multi-core processors. As CPU
malefactors reached a plateau in the clock speed due to heat issues, they
started adding more cores to CPU's to make them faster. This poses a problem
for software developers as they now have to explicitly program to
multi-processor architectures in order to reap their benefits \cite{fund}.

Concurrency refers to code which is executed simultaneously on several
processors, or cores in a single processor. Concurrent programming refers to
programming language constructs which enables code to be executed concurrently.
Concurrent code executed on a single-core processor will look like it's executed
at the same time, but in reality the processor executes increments of each piece
of code by switching back and forth between them. The way a processor switches
between concurrent tasks is referred to as context-switching, and can easily bog
down a system as the context (program state and variables) needs to be loaded
for every context-switch. Concurrent code executed on a multi-core processor
has the potential to run in parallel, e.g.\ at the same instance in
time. True concurrency can occur on a computer with either multiple processors
or one processor with multiple cores.

In most programming languages code is executed one statement at a time in a
sequential manner. Most programming languages does however include constructs
to allow for concurrent programming.  One of the most common constructs is
\textit{threads}. A thread is an abstraction for a piece of code which is
executed as a subroutine of the running program. This allows for executing
several threads concurrently or in parallel.  In
Section~\ref{sec:ruby}, the constructs available in Ruby are covered in more
detail.

Concurrency introduces several complications which must be taken into account,
mainly; race conditions and deadlocks. A race condition occurs when two or more
pieces of code tries to manipulate the same variable, and the outcome of the
program changes depending on the order of the manipulations. An example would be
if two threads, A and B, stored a counter in a global variable. Imagine thread A 
reads the value of the counter and then gets pre-empted by the scheduler and thread B changes
the counter and saves it. Then when thread A gets resumed, it would have an
incorrect counter value, and changing the counter based on this would render
thread B's previous change. Race conditions can be fixed by synchronizing access
to shared resources such as variables. A common way too synchronize access to
shared resources is to add a mutual exclusion lock (mutex) around the code which
accesses the shared resource. A mutex could ensure that only one thread uses the
shared counter variable at a time. Deadlocks can occur when shared resources gets
locked by separate threads which then each waits for the other thread to
release the resource.

Race conditions occurring in a webserver could lead to erroneous data and
deadlocks could result in the server becoming unresponsive. Hence, they should
be avoided at all costs.
